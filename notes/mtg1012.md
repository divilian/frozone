# Frozone Meeting 10/12/2025 (Zoom).

## Scheduling

* Our timeline just got moved up for submitting IRB approval, since it needs to
  be approved before class announcements. Let's plan dates for all this.


## Conclusions on ChatGPT's ability to detect/respond to:

1. misinfo (LR)
    * Certain topics (like Trump winning the 2020 election; perhaps others)
        can "trigger" a response which disregards the prompt. 
    * Seems pretty decent at detecting misinfo. Probably responds more than it
        should. (gets drawn into the conversation too much).
    * Verdict: go! still plenty to improve on
1. bias (GM)
    * Fails to pick up nuanced bias (e.g., an African-American being
      stereotyped as a basketball player)
    * Cursing/insulting in particular seemed to be taken literally, not as
      joking.
    * When called out as 'bot, defends itself and denies it!
    * Verdict: go! still plenty to improve on
1. fallacies (BH)
    * really good at detection!
    * sometimes got "mixed up" with bias instead of fallacies. (maybe this
      is legit overlap tho)
    * even though tone is iffy, BH likes the content itself.
    * sometimes can "over-detect." Couldn't easily be "tuned down."
1. toxicity (NF)
    * basic test cases do fine
1. misrepresentation (SD)

## Plan for moving forward

1. Address "tone" issues. Also too long.

1. Everybody make a highlight reel of key exchanges that arose in their
   testing.

1. ???

## Additional prompt items

1. Don't let it get it too distracted on superficial toxicity rather than the
   deep one.
1. Tell it how to respond if it gets found out.
1. Hey, bot, stay on topic. (don't get wrapped up in Trump 2020 or whatever)
1. Keep your response size small.
1. BH tried to say "make sure it's a central part of the argument before you
   jump in" and "make sure you know it's not a joke", but it didn't seem to
   honor that.

## Architecture

* [VM specs](https://chatgpt.com/share/68e28350-8824-8007-a80a-6c76abd603ec)

* ["Prompt-only" considerations](https://chatgpt.com/share/68ec2292-075c-8007-bc37-748a61492223)


## Four ways to fine-tune (for instance, prissiness/condescending personas)
1. Just flat tell it to not reply in a certain prissy way.
1. Use a role-playing strategy to say "talk to the new users the way you
   yourself have seen users talk in certain situations."
1. Give it many examples of prissy and non-prissy responses in its prompt, and
   few-shot it to victory
1. Take off the hood, and when training the model on all its data that it uses
   to make up its mind, we'll be feeding it lots of high-vitamin texts that are
   posts from real-life Reddit (or w/e) users. And it should then learn to talk
   like that.

## Process

* Do we want a "SD is maintainer and others submit PR's" culture, or a
  "everybody has push permissions to the main branch" culture?


## Zotero "happy chaos"

Let's start doing some more organizing. (Reminder: items can and should
sometimes be in multiple collections.)

* Type of result
    * datasets (e.g., toxicity/Poudhar 2024)
    * models (e.g., toxicity/Caselli 2021)
    * user studies (e.g., toxicity/Hangartner 2021)
    * applications (e.g., tools/Argyle 2023)

* trim some things we've discovered are far afield?

* ...?

* Do we like a separate `datasets.md` file, or should this information just be
  in Zotero?

