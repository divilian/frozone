# Frozone Meeting 1/22/2026

## Updates

LR: Prolific looks like a go!

BH: we have pulled the trigger on the URES grant thingy

# Problematic areas

## General thoughts

* Systemic, vs. one-offs: let's make sure we concentrate on the first, and not
  spend time "fixing" occurrences that are rare.
* Levels of disguising bot-ness: how much do we actually care? Maybe not much
  (see 2nd point under Discussion, below)
* Strategies: there are at least three ways to "fix" problematic 'bot behavior:
    a. just fix it manually, post-LLM
    a. change the prompt(s) to prohibit it
    a. weed instances of it out of the fine-tuning set and re-fine-tune

    Probably, a is easier than b which is easier than c, so let's take the
    most time-efficient approach in each case.


# Discussion

GM: instead of using our time/resources to make the bots better, we could
instead put more humans in the experiment so that it's not just bots. LR/SD/BH:
meh, but Prolific won't make this easy, plus it doesn't seem that would fix
everything anyway (if there are > 0 bots, we need to fix some issues.)

Upon reflection, SD/BH/LR/GM seem to agree that at the end of the day, hiding
the identity of the bots isn't mission critical. As long as they are
contributing appropriately to the dialogue, human chatters are likely to accept
them as fellow participants.


## General prompt thoughts

Is the prompt getting "diluted" because it's (e.g.) too early in the context
window? Answer: not sure. (And how to tell?)

Do we need two prompts -- a fine-tuning prompt and a separate inference prompt?
Decision: we're going to try this.

SD notes that the "`system`" (or "`developer`") part(s) of the input structure that OpenAI-style, role-based chat-completion models use is intended to hold priority instructions, more important and permanent than things in the "`user`" part. (Citation needed.) Therefore, we might want to put our HotBot/CoolBot/FroBot prompt text in the "`system`" and leave the conversation itself in the "`user`".

## Specific areas, and immediate approaches

1. responses too long (**BH**)
    * shorten fine-tuning examples
    * make "only 1 to 4 sentence" instruction LOUDER in the prompt
    * give prompt as "system" rather than "user" part of the messages list
1. sounds like a moderator (**LR**)
    * think/talk on this, and figure out which did we mean?:
        a. know-it-all lecture-y attitude
        b. explicitly saying "don't say that on this subreddit"
1. dash lists, numbered lists, etc. (**SD**)
    * prompt out of this (and consider 2 prompts)
1. too many references/links (**SD**)
    * prompt out of this (and consider 2 prompts)
1. revealing its identity (**BH**) (tell it not to have an identity?)
    * make sure it's a US resident
    * revisit this in the light of Prolific's breadth. find examples in
      chatlogs?
1. gets stuck or repetitive (**LR**)
    * is this a Google problem?
    * solve with fine-tuning (this was especially in coolbot's)
1. spelling/grammar too good (from SD)
    * use nlpaug
1. semicolons (from BH)
    * replace with commas? 
1. "Reddit symbols" ("`&gt;`"? other examples?) (from NF)
    * Ask NF other examples?
1. Self-contradiction, and generally completely ignoring context (from NF) HotBot making incoherent topic switches (from NF)
    * this is humans, though...right?
    * which bot was this?
    * could be Chat-generated preambles in training data (ChatGPT isn't good at
      preambling toxicity).
    * can we solve this with hand-crafting the fine-tuning data.
1. Quoting 'the article' as if there is some shared common source that they are all commenting on. (from NF) 
    * how common is this? and any thoughts on how to work around it?
1. quotes for no reason (from NF)
    * post-process out of it
1. too many "Hey, X"'s (from NF)
    * SD wonders aloud if this is really a problem. Maybe this is just FroBot's
      "style" and human users will accept it as such?
1. "Providing specific statistics, studies, or quotes that appear fabricated" (from NF)
    * prompt out of this?
1. HotBot rage bait (from NF)
    * SD wonders aloud if this is really a problem. Maybe this is exactly what
      we want HotBot to do?
1. FroBot often validates or remains overly polite toward clearly problematic statements (from NF)
    * SD wonders aloud if this is really a problem. Maybe this is exactly what
      we want FroBot to do?
1. FroBot saying "it's complicated" or "there are many perspectives" without taking any stance (from NF)
    * SD wonders aloud if this is really a problem. Maybe this is exactly what
      we want FroBot to do?

# Action items

1. Double-check that Prolific people can only "bail out" at the end, not the beginning. (**LR**)
1. Survey question revisit and revise (**LR**)
1. Decide: do we auto-stop them, or just have them time it? (**LR**)
1. Sometime convenient, take a once-through the Gao et al paper in the
   `LLM+ABM` Zotero folder. Read it medium fast. (all)

