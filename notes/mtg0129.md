# Frozone Meeting 1/29/2026

## Status of fixing various kinds of problematic bot responses

### Legend:

| Code | Status Description                                   |
|------|------------------------------------------------------|
| â€”    | Hasn't gotten to yet                                 |
| c    | In progress: writing code to do it                   |
| t    | In progress: assembling a fine-tuning dataset        |
| p    | In progress: reworking prompts to do it              |
| d    | Done (may need to be integrated into Flask app)      |
| x    | Done and verified                                    |


## highest priority

- [tp] responses too long (**BH**)
    * shorten fine-tuning examples
    * make "only 1 to 4 sentence" instruction LOUDER in the prompt
    * incorporate into two-prompt solution (don't tell FT prompt that we want
      short messages, do tell I prompt that.)
    * give prompt as "system" rather than "user" part of the messages list
- [t] sounds like a moderator (**LR**)
        explicitly saying "don't say that on this subreddit"
- [d] dash lists, numbered lists, etc. (**SD**)
    * prompt out of this (and consider 2 prompts)
- [tp] revealing its identity (**BH**) (tell it not to have an identity?)
    * make sure it's a US resident
    * revisit this in the light of Prolific's breadth. find examples in
      chatlogs?
- [ ] gets stuck (**LR**)
    * experiment with context window adjustment
    * does the system-vs-user prompt thing help?
- [d] repeats previous responses (**LR**)
    * duplicate message checker
    * is this a Google problem?
    * solve with fine-tuning (this was especially in coolbot's)

## medium priority

- [t] HotBot's self-contradiction, and incoherent topic switches (**BH**)
    * try: make a split FT set, with half multi-turn dialogues from CoolBot,
      and half toxic stuff
- [ ] too many references/links (**SD**)
    * prompt out of this (and consider 2 prompts) (coordinate with BH on
      prompting for fewer/better/real references)
- [ ] Quoting 'the article' as if there is some shared common source that they are all commenting on. (**BH**)
    * remove references to "that phantom article" in FT set
    * prompt our way out of it
- [ ] "Reddit symbols" ("`&gt;`"? other examples?) (from NF) (**SD**)
    * Ask NF other examples?

## lowest priority

- [d] spelling/grammar too good (from SD)
    * use nlpaug
- [ ] semicolons (from BH)
    * post-process it (replace with periods or commas)
- [ ] quotes for no reason (**SD**)
    * post-process out of it
- [ ] too many "Hey, X"'s (from NF) (**SD**)
    * post-process out of it
- [ ] "Providing specific statistics, studies, or quotes that appear fabricated"
    * prompt out of this?

## Let's skip these

- [ ] FroBot often validates or remains overly polite toward clearly problematic statements 
- [ ] FroBot saying "it's complicated" or "there are many perspectives" without taking any stance 

# Action items

* Make a split fine-tuning data set for HotBot: half multi-turn dialogues
  (LR-vetted) from CoolBot, and half toxic stuff from GM. (Also, just dial down
  the fine-tuning data set size?)
* Test/verify the text corruptor code
* Test/verify the humanizer code
* Test/verify the duplicate detection and removal code
