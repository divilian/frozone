# Frozone Meeting 1/15/2026. (Happy new year!)

## Stephen's retrospective take

I think we did some incredible work, and made a huge and necessary step towards
where we want to be. It was an essentially learning experience to set up what
we need to do next.

We probably rushed the Fro/Hot/Coolbot language models. There were enough
common and widely-varying kinds of errors that we need to fix, in order to
actually have experimental data worth analyzing (and publishing).

## Suggested plan for spring:

1. Weeks 1-2
    1. The Identifying Problems task: Go through the chatlogs, looking for all
       instances of "obviously undesirable behavior" (categorized below). The
       action item here is "find instances of the problem in the chatlogs,
       highlight them, and do some deep thinking about 'how could we fix this
       in prompt? fine-tuning data? how can we tell that we've fixed it?'"
       * responses too long (BH)
       * sounds like a moderator (LR)
       * dash lists, numbered lists, etc. (SD)
       * too many references/links (SD)
       * revealing its identity (BH) (tell it not to have an identity?)
       * gets stuck or repetitive (LR)
    1. Spend time deliberately "fine-tuning-out" or "prompting-out" those
       problems. Spend enough time with the re-tuned models to feel comfortable
       that those problems will not recur.
    1. Go through the surveys to get an overall idea of what other easy things
       might be worth trying to change.
    1. Figure out how to recruit [Prolific](https://www.prolific.com/) users,
       and set up an account (or whatever).
    1. Get IRB amended approval, if necessary, for Prolific.
1. Week 3
    1. Deploy the experiment to ~25 Prolific users.
1. Week 4
    1. Annotate _those_ chat logs, compute inter-rater agreement, etc. Analyze
       _those_ surveys.
1. Weeks 5-6
    1. Take stock of where we are. Do we want to write the experiment paper
       now, or dive in to ABMs more eagerly.
    1. (Maybe) write and submit "**the experiment paper**."
1. Weeks 7-8
    1. Get up to speed on ABMs, and LLM integration.
    1. Background reading (lit search) on LLM-ABMs, especially in this
       political space.
1. Weeks 9-10
    1. Design ABM model.
    1. Develop strategy for synthesizing social network.
    1. Develop approach for synthesizing LLM agent personas.
    1. Design LLM prompts.
    1. Identify independent and dependent variables.
    1. Create simulation plan.
1. Weeks 11
    1. Carry out and babysit simulations. Drain the earth of resources.
1. Weeks 12-14
    1. Analyze simulation results
    1. Write and submit "**the ABM paper**."
1.

# Action items

1. Glance through the chat logs and make sure that the above list contains all
   the types of "problem responses" we want to eradicate. (SD/LR/BH/GM)
1. Do the deep thinking expressed in The Identify Problems Task. (SD/LR/BH)
1. Confirm that Gemini is as customizable as we're going to want it to be. What
   are knobs that we might need to tune to get it to behave properly. (GM)
1. Curate smaller Reddit datasets (200 responses) out of "known good (and
   good length) responses," from:
   1. Coolbot (LR)
   1. HotBot (BH)
   1. FroBot?? (GM??)
1. Clean up **and comment** the code base. (Be careful not to break anything!)
   (GM)
1. Code review the code base, including GM's changes. (SD/LR/BH)
1. Write our own (even smaller) Reddit dataset (20 responses) by hand. (GM)
1. Investigate Prolific and figure out how we can use it, estimate cost, etc.
   (LR)
1. Sometime convenient, take a once-through the Gao et al paper in the
   `LLM+ABM` Zotero folder. Read it medium fast. (all)
