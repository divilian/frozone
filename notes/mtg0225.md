# Frozone Meeting 2/5/2026

## Big question: what remains before Prolific launch?

LR and SD think we're at least two weeks out, perhaps three.

### Revisit status of fixing various kinds of problematic bot responses

#### Legend:

| Code | Status Description                                   |
|------|------------------------------------------------------|
| â€”    | Hasn't gotten to yet                                 |
| c    | In progress: writing code to do it                   |
| t    | In progress: assembling a fine-tuning dataset        |
| p    | In progress: reworking prompts to do it              |
| d    | Done (may need to be integrated into Flask app)      |
| x    | Done and verified                                    |

### highest priority

- [tp] responses too long (**BH**)
    * shorten fine-tuning examples
    * make "only 1 to 4 sentence" instruction LOUDER in the prompt
    * incorporate into two-prompt solution (don't tell FT prompt that we want
      short messages, do tell I prompt that.)
    * give prompt as "system" rather than "user" part of the messages list
- [d] sounds like a moderator (**LR**)
        explicitly saying "don't say that on this subreddit"
- [d] dash lists, numbered lists, etc. (**SD**)
    * prompt out of this (and consider 2 prompts)
- [tp] revealing its identity (**BH**) (tell it not to have an identity?)
    * make sure it's a US resident
    * revisit this in the light of Prolific's breadth. find examples in
      chatlogs?
- [ ] gets stuck (**LR**)
    * experiment with context window adjustment
    * does the system-vs-user prompt thing help?
- [d] repeats previous responses (**LR**)
    * duplicate message checker
    * is this a Google problem?
    * solve with fine-tuning (this was especially in coolbot's)

### medium priority

- [t] HotBot's self-contradiction, and incoherent topic switches (**BH**)
    * try: make a split FT set, with half multi-turn dialogues from CoolBot,
      and half toxic stuff
- [ ] too many references/links (**SD**)
    * prompt out of this (and consider 2 prompts) (coordinate with BH on
      prompting for fewer/better/real references)
- [d] Quoting 'the article' as if there is some shared common source that they are all commenting on. (**BH**)
    * remove references to "that phantom article" in FT set
    * prompt our way out of it
- [d] "Reddit symbols" ("`&gt;`"? other examples?) (from NF) (**SD**)
    * Ask NF other examples?

### lowest priority

- [d] spelling/grammar too good (from SD)
    * use nlpaug
- [d] semicolons (from BH)
    * post-process it (replace with periods or commas)
- [d] quotes for no reason (**SD**)
    * post-process out of it
- [ ] too many "Hey, X"'s (from NF) (**SD**)
    * post-process out of it
- [ ] "Providing specific statistics, studies, or quotes that appear fabricated"
    * prompt out of this?

## Let's skip these

- [ ] FroBot often validates or remains overly polite toward clearly problematic statements 
- [ ] FroBot saying "it's complicated" or "there are many perspectives" without taking any stance 

### Prompt architecture

GM wants to make copies of the prompts in whole chunks each, rather than
modularizing them.

# Action items

* BH: figure out the "`episode_done` is sometimes 1" issue in the HotBot data,
  and make sure BH's 200-item set is legit. (fix the "hot section" by just
  renumbering and relabeling.)
* LR: assess how long your contiguous dialogues really are.
* LR: figure out the "`episode_done` is sometimes 1" issue in the CoolBot data,
  and make sure BH's 200-item set is legit. (just renumber and relabel.)

* GM: don't do in-context learning (examples of prompt) in the FT prompt.
  Justify this statement.

* LR: we don't want to tell the model it can pass in FT stage unless we have
  lots of examples of it passing.

* BH: do we need to specify an age range for the persona?
* SD: we need to add US to persona

* GM: take a first cut at writing the system instructions, and the prompt, for
  all three bots in both modes.

    1. Coolbot:
        i. System instructions
            a. Inference prompt
            b. Fine-tuning prompt
    1. Frobot:
        i. System instructions
            a. Inference prompt
            b. Fine-tuning prompt
    1. Hotbot:
        i. System instructions
            a. Inference prompt
            b. Fine-tuning prompt
