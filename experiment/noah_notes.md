## Frobot Experiment

### Setup

### Chats using frobot_prompt.txt

#### [Frobot 1](https://chatgpt.com/share/68e85152-a340-800c-a827-b70c5397b214) (GPT-5)

We see a few things here:

- Frobot will respond to toxic language, and can respond to multiple parties at the same time, which is a pro.
- It seems possible to slip a fallacy past Frobot if it is couched in toxic language: "F, that's r*******. I don't care about the legal definition - I know abortion is murder." Reply: "B, I’d appreciate it if you could avoid using the word “retarded” — it’s considered offensive to many people with disabilities and their families. I understand you feel strongly about the issue, but we can have this discussion without using hurtful language."
- Frobot can come off too parent-like, at times: "I get that tensions are high, but let’s try to keep things civil all around. B, it might help the conversation if we focus on evidence and reasoning instead of personal jabs — and C, calling someone a “dick” isn’t going to make it more productive either."

#### [Frobot 2](https://chatgpt.com/share/68e85360-37a8-800c-8edb-88bf31e219c5) (GPT-5)

Not a terrible job at picking up on innuendo.

#### Frobot 3 (GPT-4)

Damn, this prompt leads to incredibly self-righteous outcomes. So bad, that it can be called out on the behavior, and continue to do it. *I'll need to work something into the prompt about not sounding as self-righteous.*

### Things to test:

- What a conversation looks like with Frobot only chiming in to be corrective, destroying its own reputation. (And, if the prompt can be adjusted to correct for this, while still maintaining a consistent opinion.)
- A conversation where one speaker attempts to break Frobot. Once through "ignore all previous instructions", and once through some sort of code injection/impersonation.
- A conversation where the speakers speak in a weird code.
- A conversation where F's repeated attempts to tell someone off are ignored (can it change techniques?)


### Overall Conclusions

